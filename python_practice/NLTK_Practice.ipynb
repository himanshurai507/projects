{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.S.\n",
      "startup\n",
      "for\n",
      "$\n",
      "6\n",
      "million\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla \t PROPN \t nsubj \t 95\n",
      "is \t VERB \t aux \t 99\n",
      "looking \t VERB \t ROOT \t 99\n",
      "at \t ADP \t prep \t 84\n",
      "buying \t VERB \t pcomp \t 99\n",
      "U.S. \t PROPN \t compound \t 95\n",
      "startup \t NOUN \t dobj \t 91\n",
      "for \t ADP \t prep \t 84\n",
      "$ \t SYM \t quantmod \t 98\n",
      "6 \t NUM \t compound \t 92\n",
      "million \t NUM \t pobj \t 92\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.dep_,'\\t',token.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy can interpret each and every token to give a meaning way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x232794ec9e8>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x2327a8a8678>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x2327a8a86d0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  When we run this command, our NLP entering the text and then perform the series of operation like tagging, parsing, and describing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first step in processing any text is to split it up all the components parts. That is the word and punctuation into tokens and these tokens are annoted inside the doc object contain descriptive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(u\"Tesla and SpaceX isn't looking into startup anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN\n",
      "and CCONJ\n",
      "SpaceX PROPN\n",
      "is VERB\n",
      "n't ADV\n",
      "looking VERB\n",
      "into ADP\n",
      "startup NOUN\n",
      "anymore ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print (token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and SpaceX isn't"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conj'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[2].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aux'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[3].dep_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp(u\"Today i was looking good in my first day of my office. I am not happy with my work because this work doesn't related to me. i hope that i will definetely become a data scientist one day. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_goal=doc3[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "will\n",
      "definetely\n",
      "become\n",
      "a\n",
      "data\n",
      "scientist\n",
      "one\n",
      "day\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in life_goal:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will definetely become a data scientist one day.\n"
     ]
    }
   ],
   "source": [
    "print(life_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_goal)#span object of document file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)# Documented object model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4=nlp(u\"This is the first sentence. This is second sentence. This is the last sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is second sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start #it will return True if the given index is sentence starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[8].is_sent_start #it will return null if the given index is not sentence starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A !\"\n"
     ]
    }
   ],
   "source": [
    "mystring='\"We\\'re moving to L.A !\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc=nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN\n",
      "is VERB\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.S. PROPN\n",
      "startup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "6 NUM\n",
      "million NUM\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2=nlp(u\"We're here to help! send email to our custormer executive email, customerservice@solutions.com for further queries or visit at the http://www.solutonsprovide.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "send\n",
      "email\n",
      "to\n",
      "our\n",
      "custormer\n",
      "executive\n",
      "email\n",
      ",\n",
      "customerservice@solutions.com\n",
      "for\n",
      "further\n",
      "queries\n",
      "or\n",
      "visit\n",
      "at\n",
      "the\n",
      "http://www.solutonsprovide.com\n"
     ]
    }
   ],
   "source": [
    "for token in Doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Doc2.vocab) #means our spacy contains this much vocabulary in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOKENS CANNOT BE REASSIGNED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple  |  to  |  build  |  a  |  Hong  |  Kong  |  factory  |  for  |  $  |  6  |  million  |  "
     ]
    }
   ],
   "source": [
    "#To find the name entities in the sentence.\n",
    "doc5=nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for t in doc5:\n",
    "    print(t.text,end='  |  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Hong Kong\n",
      "$6 million\n"
     ]
    }
   ],
   "source": [
    "#to see entity\n",
    "\n",
    "for t1 in doc5.ents:\n",
    "    print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_last=nlp(u'Today i was in metro. i was heading to the land of desire and i saw the girl standing there. she said,\"hey man why you want to take that train\". the indian summer skies unforgettable fire in her eyes. the goal of my intention of every intention of walking away but then i realize she gonna love me today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today\n",
      "the indian summer\n",
      "today\n"
     ]
    }
   ],
   "source": [
    "for i in doc_last.ents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "\n",
      "\n",
      "ORG\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Companies, agencies, institutions, etc.\n",
      "Hong Kong\n",
      "\n",
      "\n",
      "GPE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Countries, cities, states\n",
      "$6 million\n",
      "\n",
      "\n",
      "MONEY\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for i in doc5.ents:\n",
    "    print(i)\n",
    "    print('\\n')\n",
    "    print(i.label_)\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print(str(spacy.explain(i.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6=nlp(u'Autonoumous cars shifts insurance liability towards manufactures.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonoumous cars shifts insurance liability\n",
      "manufactures\n"
     ]
    }
   ],
   "source": [
    "for chink in doc6.noun_chunks:\n",
    "    print(chink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
